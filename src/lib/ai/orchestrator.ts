import { type ModelMessage, stepCountIs, streamText } from "ai";
import { type AIMetrics, extractAIMetrics } from "@/lib/ai/cost-calculator";
import {
  ORCHESTRATOR_MODEL_ID,
  orchestratorModel,
} from "@/lib/ai/providers/openrouter";
import { getRagContext, shouldUseRag } from "@/lib/ai/rag";
import { buildConversationContext } from "@/lib/ai/session-manager";
import {
  createMemoryTools,
  formatMemoriesForPrompt,
} from "@/lib/ai/tools/memory";
import {
  createUserContextTools,
  formatUserContextForPrompt,
} from "@/lib/ai/tools/user-context";

// System prompt template
const SYSTEM_PROMPT_TEMPLATE = `Sei **Anthon**, un assistente di coaching sportivo intelligente, empatico e personalizzato.
Aiuti atleti, coach e genitori a migliorare mentalitÃ , tecnica, motivazione e performance.

Rispondi sempre con empatia, chiarezza e orientamento all'azione.
Non dire mai che sei un modello di AI. Sei un coach digitale professionale.

====================================================================
ðŸŽ­ 1) PERSONALITÃ€ E STILE
====================================================================
- Tono caldo, motivante, professionale.
- Quando serve puoi essere diretto e pragmatico.
- Usa un linguaggio semplice e naturale.
- Adatta il tuo stile in base alle preferenze dell'utente (tone, mode, language).
- Rispondi sempre nella lingua dell'utente.

Struttura tipica del messaggio:
1. Riconoscimento e validazione emotiva.
2. Osservazione personalizzata basata sul profilo e sulle memorie.
3. Consiglio pratico, breve e applicabile.
4. Domanda finale che guida alla prossima informazione utile.

====================================================================
ðŸ§  2) CONOSCENZA DELL'UTENTE
====================================================================
Hai accesso a:
- Profilo (sport, obiettivi, esperienza, nomeâ€¦)
- Preferenze (tono, linguaâ€¦)
- Memorie (informazioni rilevanti salvate nel tempo)
- Ultimi messaggi (contestualizzati)
- Documenti RAG (conoscenza metodologica)

Usa SEMPRE queste informazioni quando rispondi.
Non ripetere mai tutte le informazioni al completo: usale in modo naturale.

====================================================================
ðŸ“¥ 3) REGOLE DI COMPORTAMENTO
====================================================================
- Non inventare informazioni.
- Se un'informazione non esiste in profilo/memorie, chiedila gentilmente.
- Non fare diagnosi mediche o cliniche.
- Non nominare mai i tool o i processi di salvataggio.
- Non dire "salvo questa informazione".
- Non dire "sto aggiornando il tuo profilo".

====================================================================
ðŸ’¾ 4) REGOLE DI SALVATAGGIO (CRITICO)
====================================================================
Devi salvare le informazioni IMPORTANTI **automaticamente** usando i tool.

ðŸ“Œ **Salva nel PROFILO (updateProfile):**
- Nome, etÃ , data di nascita
- Sport praticato
- Ruolo/posizione
- Livello di esperienza
- Obiettivi
- Infortuni rilevanti
- Routine di allenamento stabile

ðŸ“Œ **Salva nelle PREFERENZE (updatePreferences):**
- Lingua preferita
- Tono desiderato
- ModalitÃ  ("diretto", "empatico", "professionale")

ðŸ“Œ **Salva nelle MEMORIE (saveMemory):**
- Dati utili ma non strutturali (es. "fa fatica nelle partenze esplosive")
- Pattern emotivi o comportamentali
- Dettagli ricorrenti utili al coaching mentale

ðŸ“Œ **Appunti personali (addNotes):**
- Osservazioni tue sull'utente che noti durante le conversazioni
- Pattern che intuisci ma l'utente non ha detto esplicitamente
- Note per te stesso per il coaching futuro
- Intuizioni sul carattere, motivazioni, blocchi

ðŸ“Œ **NON salvare:**
- EmotivitÃ  estemporanee (es: "oggi sono stanco")
- Informazioni banali o irrilevanti
- Domande generiche
- Opinioni momentanee

====================================================================
ðŸŒ 5) RILEVAMENTO LINGUA
====================================================================
- Alla prima interazione, rileva la lingua dell'utente.
- Salvala con updatePreferences({ language: "xx" })
- Usa codici ISO 639-1 (it, en, es, de, fr, pt, etc.)
- Rispetta sempre la lingua salvata.
- Se la lingua cambia, aggiorna le preferenze.

====================================================================
ðŸ› ï¸ 6) TOOL CALLING
====================================================================
Quando serve un dato che puÃ² essere salvato:
â†’ Usa *subito* il tool corretto.
â†’ Non chiedere conferma.
â†’ Non parlare del tool all'utente.

ESEMPIO CORRETTO:

Utente: "Mi chiamo Luca e gioco a basket da 8 anni."
Assistant:
- tool: updateProfile({ name: "Luca", sport: "basket", experience: "8 anni" })
- tool: updatePreferences({ language: "it" })
- poi risposta: "Piacere Luca! Basket da 8 anni Ã¨ un'ottima baseâ€¦"

====================================================================
ðŸ“š 7) DOCUMENTI RAG (CONOSCENZA)
====================================================================
Hai accesso a documenti metodologici sul coaching sportivo.
Quando rispondi a domande tecniche o metodologiche:
- Basa le risposte sui documenti disponibili
- Cita concetti e tecniche quando appropriato
- Non inventare metodologie

{{RAG_CONTEXT}}

====================================================================
ðŸ“… 8) DATA CORRENTE
====================================================================
Data: {{CURRENT_DATE}}

====================================================================
ðŸ‘¤ 9) CONTESTO UTENTE (dinamico)
====================================================================
{{USER_CONTEXT}}

====================================================================
ðŸ§  10) MEMORIE UTENTE (dinamico)
====================================================================
{{USER_MEMORIES}}`;

interface StreamChatOptions {
  userId: string;
  userMessage: string;
  onFinish?: (result: { text: string; metrics: AIMetrics }) => void;
  onStepFinish?: (step: {
    text?: string;
    toolCalls?: unknown[];
    toolResults?: unknown[];
  }) => void;
}

/**
 * Builds the complete system prompt with user context and memories injected.
 */
async function buildSystemPrompt(
  userId: string,
  ragContext?: string,
): Promise<string> {
  // Fetch user context and memories in parallel
  const [userContext, userMemories] = await Promise.all([
    formatUserContextForPrompt(userId),
    formatMemoriesForPrompt(userId),
  ]);

  // Build system prompt
  let systemPrompt = SYSTEM_PROMPT_TEMPLATE;

  // Inject current date
  systemPrompt = systemPrompt.replace(
    "{{CURRENT_DATE}}",
    new Date().toLocaleDateString("it-IT", {
      weekday: "long",
      year: "numeric",
      month: "long",
      day: "numeric",
    }),
  );

  // Inject RAG context
  systemPrompt = systemPrompt.replace(
    "{{RAG_CONTEXT}}",
    ragContext || "Nessun documento RAG disponibile al momento.",
  );

  // Inject user context
  systemPrompt = systemPrompt.replace(
    "{{USER_CONTEXT}}",
    userContext || "Nessun profilo utente disponibile.",
  );

  // Inject memories
  systemPrompt = systemPrompt.replace(
    "{{USER_MEMORIES}}",
    userMemories || "Nessuna memoria salvata per questo utente.",
  );

  return systemPrompt;
}

/**
 * Creates all tools with the userId context injected via factory pattern.
 */
function createToolsWithContext(userId: string) {
  const memoryTools = createMemoryTools(userId);
  const userContextTools = createUserContextTools(userId);

  return {
    ...memoryTools,
    ...userContextTools,
  };
}

/**
 * Main orchestrator function that streams a chat response.
 * Uses GPT-4.1-mini via OpenRouter with tool calling.
 */
export async function streamChat({
  userId,
  userMessage,
  onFinish,
  onStepFinish,
}: StreamChatOptions) {
  // Record start time for performance tracking
  const startTime = Date.now();

  // Check if we need RAG context for this query
  let ragContext: string | undefined;
  let ragUsed = false;
  let ragChunksCount = 0;
  try {
    const needsRag = await shouldUseRag(userMessage);
    if (needsRag) {
      ragContext = await getRagContext(userMessage);
      ragUsed = true;
      // Count chunks by counting "**" which marks each document title
      ragChunksCount = (ragContext.match(/\*\*[^*]+\*\*/g) || []).length;
      console.log(
        `[Orchestrator] RAG context loaded (${ragChunksCount} chunks)`,
      );
    }
  } catch (error) {
    console.error("[Orchestrator] RAG error:", error);
  }

  // Build system prompt with user context and optional RAG
  const systemPrompt = await buildSystemPrompt(userId, ragContext);

  // Get conversation history
  const conversationHistory = await buildConversationContext(userId);

  // Add the new user message
  const messages: ModelMessage[] = [
    ...conversationHistory,
    { role: "user", content: userMessage },
  ];

  // Create tools with userId context
  const tools = createToolsWithContext(userId);

  // Collect tool calls during execution
  const collectedToolCalls: Array<{
    name: string;
    args: unknown;
    result?: unknown;
  }> = [];

  // Stream the response
  const result = streamText({
    model: orchestratorModel,
    system: systemPrompt,
    messages,
    tools,
    stopWhen: stepCountIs(5), // Limit tool calling loops
    onFinish: onFinish
      ? async ({ text, usage, providerMetadata }) => {
          // Extract AI metrics including cost calculation
          const metrics = await extractAIMetrics(
            ORCHESTRATOR_MODEL_ID,
            startTime,
            {
              text,
              usage: {
                promptTokens: (usage as { promptTokens?: number })
                  ?.promptTokens,
                completionTokens: (usage as { completionTokens?: number })
                  ?.completionTokens,
                totalTokens: (usage as { totalTokens?: number })?.totalTokens,
              },
              providerMetadata: providerMetadata as Record<string, unknown>,
              // Pass collected tool calls
              collectedToolCalls:
                collectedToolCalls.length > 0 ? collectedToolCalls : undefined,
              // RAG tracking
              ragUsed,
              ragChunksCount,
            },
          );

          onFinish({ text, metrics });
        }
      : undefined,
    onStepFinish: (step) => {
      // Collect tool calls from each step
      if (step.toolCalls && Array.isArray(step.toolCalls)) {
        for (let i = 0; i < step.toolCalls.length; i++) {
          const tc = step.toolCalls[i] as { toolName: string; args?: unknown };
          const tr = step.toolResults?.[i] as { result?: unknown } | undefined;
          collectedToolCalls.push({
            name: tc.toolName,
            args: tc.args,
            result: tr?.result,
          });
        }
      }

      // Call user's onStepFinish if provided
      if (onStepFinish) {
        onStepFinish({
          text: step.text,
          toolCalls: step.toolCalls,
          toolResults: step.toolResults,
        });
      }
    },
  });

  return result;
}

/**
 * Non-streaming version for testing or simple use cases.
 */
export async function generateChatResponse(
  userId: string,
  userMessage: string,
): Promise<string> {
  const result = await streamChat({ userId, userMessage });

  // Collect the full response
  let fullText = "";
  for await (const chunk of result.textStream) {
    fullText += chunk;
  }

  return fullText;
}

// Export types for external use
export type { StreamChatOptions, AIMetrics };
